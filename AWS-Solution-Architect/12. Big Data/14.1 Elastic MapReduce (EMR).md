[[Big Data]]

## What is ETL?
- Stands for extract, transform, and load are processes data management and analysis

## What is EMR?
- Stands for Elastic MapReduce, meant to provide an easier way to manage infrastructure and run playbooks for ETL processes in cloud

## EMR Storage:

There are 3 types:
- Hadoop Distributed File System (HDFS): Used for caching result during processing
- EMR File System (EMRFS): Used to store input and output data, not intermediate data
- Local file system: Locally connected disk created with each EC2 instance

## EMR Cluster and Nodes

Cluster are group of EC2 within EMR. Each instance is a node
- Primary node: Manages the cluster,  coordinates distribution of data, task, and track health status
- Core node: Run tasks and stores data in HDFS. Long-running!
- Task node: ONLY run task with no storage of data within HDFS. Typically spot instances

# Exam Tips

- What is EMR? AWS managed big data platform that allows to process vast amounts of data
- EC2 purchasing rule apply: On-demand, reserved, spot instances
- Toolsets to remember: Built-in support for Spark, Hive, HBase, Flink, Hudi, and Presto
- Big data framework: Keep an eye on Apache Hadoop and Apache Spark
- Store type: Keyword can include Hadoop Distributed File system (HDFS) and EMR File system (EMRFS)
- Use cases and scenarios: Large dataset processing (ELT), web indexing, machine learning training, and large-scale genomics